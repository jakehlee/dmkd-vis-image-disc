# Visualizing Image Content to Explain Novel Image Discovery
### Jake Lee, Kiri Wagstaff
### Under Preparation

This repository contains supplemental scripts and data used in the experiments presented in the paper.

This repository uses git-lfs to store model weights. Install git-lfs [here](https://git-lfs.github.com).

## Step-by-step instructions for running experiments

1. **Compile the image data set** - It is recommended that the image filename include the class information. The images can be in class subfolders or in a single folder.

2. **Preprocess the imageset** - We recommend scaling and center-cropping your images to 227x227 first.

	We used imagemagick: `mogrify -path imageset/# -format jpg -resize "227x227^" -gravity center -crop 227x227+0+0 +repage imageset/#/*.jpg`

	Caffe also provides a tool: https://github.com/BVLC/caffe/blob/master/tools/extra/resize_and_crop_images.py

3. **Download and install DEMUD** - Available at https://github.com/wkiri/DEMUD

4. **Extract features** - Extract features from the images using `DEMUD/scripts/cnn_feat_extraction/feat_csv.py`. The extracted features will be saved as a CSV, with the first column being the image name.

	You will need to install Caffe and specify the trained Caffe model from which the features will be extracted.  We used Caffe's pre-trained model called `bvlc_reference_caffenet` with a modified `deploy.prototxt`.

	The pre-trained model is available at https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_caffenet.

	The modified prototxt is available in this repository at `src/extract/deploy.prototxt`.

5. **Run DEMUD on features** - Configure DEMUD by adding the path to the feature CSV in `demud.config` at the `floatdatafile` line.

	Run DEMUD. An example run: `python demud.py -v --init-item=svd --n=300 --k=4096 --svdmethod=increm-brand --note=balfc6`

	- `-v` indicates this is a run on CNN features in a CSV
	- `--init-item=svd` sets the first item initialization to full SVD initialization.
	- `--n=300` sets DEMUD to select the first 300 items.
	- `--k=4096` sets the number of principal components used during SVD to a maximum of 4096.
	- `--svdmethod=increm-brand` sets the SVD method to incremental SVD as described by Brand, 2002.
	- `--note=balfc6` will append "balfc6" to the end of the results directory.

6. **Visualize the explanations** - Use `src/visualize/vis_DEMUD.py` to generate visualizations of the explanations. This script and its associated models were modified and trained from code provided for Dosovitskiy and Brox, 2016 (NIPS). The original source is available [here](https://lmb.informatik.uni-freiburg.de/resources/software.php).

7. **Calculate and plot discovery rates** - Use `src/util/calc_auc.py` and `src/util/plot_exp.py` to calculate nAUCt scores and generate discovery plots.

8. **Organize results** - Use `src/util/gen_html.py` to generate PDFs to display selected images and visualized explanations.

## Scripts

`src/extract/deploy.prototxt` is a modified prototxt for the model `bvlc_reference_caffenet`. Originally, the model performs ReLU in-place, overwriting the `fc6` and `fc7` blobs in the process. Our modified prototxt instead writes post-ReLU values to the `relu6` and `relu7` blobs, allowing us to extract pre-ReLU activation values.

----

`src/visualize/vis_DEMUD.py`

Usage: `python vis_DEMUD.py NET_NAME EXP_PATH EXP_NAME`

* `NET_NAME` is the directory name of the model to visualize with. The `fc6-6e5`, `fc7-6e5`, and `fc8` models have been provided to visualize explanations from the corresponding representations.
* `EXP_PATH` is the path to the directory that contains results from DEMUD. The directory name should begin with `cnn-k=...`
* `EXP_NAME` is a user-specified name for the experiment. A directory with this name will be created in the current path to store the visualizations.

----

`src/util/calc_auc.py`

Usage: `python calc_auc.py`

This script calculates the nAUCt metric as specified in the paper. It will calculate the nAUCt of multiple experiments stored in the same directory. Parameters, including the results directory, `n`, and `t`, must be specified within the script. A function must be provided to extract the class label from each line in the `selections.csv` generated by DEMUD. It will also calculate the nAUCt of random selection provided the quantity of images per class (`RAND_QTY`). 

----

`src/util/plot_exp.py`

Usage: `python plot_exp.py`

This script was used to generated the discovery plots shown in the paper. Parameters must be set within the script, similarly to `calc_auc.py`. Note that, because this script was developed specifically for our set of experiments, it may be difficult to adapt to other experiments. 

----

`src/util/gen_html.py`

Usage: `python gen_html.py`

This script collects the results from DEMUD and visualizations into a single HTML file for convenient viewing. The following parameters must be set within the script.

* `outputname` defines the path of the html file generated.
* `imageset_dir` defines the directory containing the full imageset.
* `dosov_dir` defines the directory containing the visualizations generated by `vis_DEMUD.py`.
* `demud_path` defines the path of the `selections.csv` output from DEMUD.

## Data

##### ImageNet-Random
`data/build-imagenet-random` provides the scripts necessary to compile the ImageNet-Random balanced and imbalanced subsets of the ILSVRC2012 training set. The ILSVRC2012 training set must be downloaded. `random_classes.txt` contains the class definitions for the ImageNet-Random data set.

`python build_balanced.py` will compile the balanced variant of the ImageNet-Random data set. `python build_imbalanced.py` will compile the imbalanced variant. The following parameters must be set within the script.

* `ilsvrc` defines the directory path of the ILSVRC2012 training set.
* `output` defines the directory in which the data set will be compiled.
* `targets` defines the filepath of the class definitions. For ImageNet-Random, this should be `random_classes.txt`.

----

##### ImageNet-Yellow
`data/build-imagenet-yellow` provides the scripts necessary to compile the ImageNet-Yellow subset of the ILSVRC2012 training set. The ILSVRC2012 training set must be downloaded. `yellow_classes.txt` contains the class definitions for the ImageNet-Yellow data set.

`python build_yellow.py` will compile the ImageNet-Yellow data set. The same parameters as `build_balanced.py` must be set within the script.

----

##### Mars-Curiosity
24 classes of the Mars-Curiosity data set can be accessed on Zenodo at https://zenodo.org/record/1049137. An additional class of 21 images, "sun", was added for our experiments, for a total of 25 classes with 6712 images. This additional class is included in `data/mars-sun-class/`

----

##### STONEFLY9
The STONEFLY9 data set can be access at http://web.engr.oregonstate.edu/~tgd/bugid/stonefly9/.











